#!/usr/bin/env python3
"""
Milvus å®Œæ•´åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import numpy as np
from pymilvus import (
    connections,
    utility,
    FieldSchema,
    CollectionSchema,
    DataType,
    Collection,
)

# é…ç½®å‚æ•°
MILVUS_HOST = "localhost"
MILVUS_PORT = "19530"
COLLECTION_NAME = "test_collection"
DIM = 768  # å‘é‡ç»´åº¦

def main():
    """ä¸»æµ‹è¯•æµç¨‹"""

    print("=" * 60)
    print("Milvus å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)

    try:
        # 1. è¿æ¥ Milvus
        print(f"\nğŸ”— è¿æ¥åˆ° Milvus ({MILVUS_HOST}:{MILVUS_PORT})...")
        connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)
        print("âœ… è¿æ¥æˆåŠŸï¼")

        # 2. åˆ é™¤æ—§é›†åˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if utility.has_collection(COLLECTION_NAME):
            print(f"\nâš ï¸  é›†åˆ '{COLLECTION_NAME}' å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤...")
            utility.drop_collection(COLLECTION_NAME)

        # 3. åˆ›å»ºé›†åˆ
        print(f"\nğŸ“¦ åˆ›å»ºé›†åˆ: {COLLECTION_NAME}")
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=512),
            FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=DIM)
        ]
        schema = CollectionSchema(fields=fields, description="æµ‹è¯•é›†åˆ")
        collection = Collection(name=COLLECTION_NAME, schema=schema)
        print(f"âœ… é›†åˆ '{COLLECTION_NAME}' åˆ›å»ºæˆåŠŸï¼")

        # 4. æ’å…¥æ•°æ®
        print(f"\nğŸ“ æ’å…¥ 100 æ¡æµ‹è¯•æ•°æ®...")
        texts = [f"è¿™æ˜¯ç¬¬ {i} æ¡æµ‹è¯•æ–‡æœ¬" for i in range(100)]
        embeddings = np.random.rand(100, DIM).tolist()
        entities = [texts, embeddings]
        insert_result = collection.insert(entities)
        print(f"âœ… æˆåŠŸæ’å…¥ {len(insert_result.primary_keys)} æ¡æ•°æ®")

        # 5. åˆ›å»ºç´¢å¼•
        print(f"\nğŸ” ä¸ºé›†åˆåˆ›å»ºç´¢å¼•...")
        index_params = {
            "metric_type": "L2",
            "index_type": "IVF_FLAT",
            "params": {"nlist": 128}
        }
        collection.create_index(field_name="embedding", index_params=index_params)
        print("âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸï¼")

        # 6. åŠ è½½é›†åˆ
        print(f"\nğŸ’¾ åŠ è½½é›†åˆåˆ°å†…å­˜...")
        collection.load()
        print("âœ… é›†åˆå·²åŠ è½½")

        # 7. å‘é‡æ£€ç´¢
        print(f"\nğŸ” æ‰§è¡Œå‘é‡æ£€ç´¢ï¼ˆTop 5ï¼‰...")
        query_vectors = np.random.rand(2, DIM).tolist()
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}
        results = collection.search(
            data=query_vectors,
            anns_field="embedding",
            param=search_params,
            limit=5,
            output_fields=["text"]
        )

        for i, result in enumerate(results):
            print(f"\næŸ¥è¯¢ {i+1} çš„ç»“æœ:")
            for j, hit in enumerate(result):
                print(f"  Top {j+1}: ID={hit.id}, è·ç¦»={hit.distance:.4f}, æ–‡æœ¬={hit.entity.get('text')}")

        print(f"\nâœ… æ£€ç´¢å®Œæˆï¼")

        # 8. è·å–ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“Š é›†åˆç»Ÿè®¡ä¿¡æ¯:")
        collection.flush()
        stats = collection.num_entities
        print(f"  - å®ä½“æ•°é‡: {stats}")
        print(f"  - é›†åˆåç§°: {collection.name}")

        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        connections.disconnect("default")
        print("\nğŸ”Œ è¿æ¥å·²æ–­å¼€")

if __name__ == "__main__":
    main()
